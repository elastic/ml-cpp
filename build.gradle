description = 'Builds the Machine Learning native binaries'

import org.gradle.internal.os.OperatingSystem
import org.gradle.plugins.ide.eclipse.model.SourceFolder
import org.gradle.util.DistributionLocator
import org.gradle.util.GradleVersion

import java.util.zip.ZipFile

import static org.gradle.api.tasks.wrapper.Wrapper.DistributionType

String versionQualifier = System.getProperty("build.version_qualifier", "")
boolean isSnapshot = "true".equals(System.getProperty("build.snapshot", "true"))
String mlDebug = System.getProperty("build.ml_debug", "")

boolean isWindows = OperatingSystem.current().isWindows()
boolean isLinux = OperatingSystem.current().isLinux()
boolean isMacOsX = OperatingSystem.current().isMacOsX()

allprojects {
  group = 'org.elasticsearch.ml'
  version = elasticsearchVersion
  if (versionQualifier != "") {
    version += '-' + versionQualifier
  }
  if (isSnapshot) {
    version += '-SNAPSHOT'
  }
}

// Secret key and access key are only needed when
// using the upload tasks near the end of this file.
String envMlAwsAccessKey = System.env.ML_AWS_ACCESS_KEY
if (envMlAwsAccessKey != null) {
  project.ext.mlAwsAccessKey = envMlAwsAccessKey
} else if (project.hasProperty('ML_AWS_ACCESS_KEY')) {
  project.ext.mlAwsAccessKey = ML_AWS_ACCESS_KEY
}

String envMlAwsSecretKey = System.env.ML_AWS_SECRET_KEY
if (envMlAwsSecretKey != null) {
  project.ext.mlAwsSecretKey = envMlAwsSecretKey
} else if (project.hasProperty('ML_AWS_SECRET_KEY')) {
  project.ext.mlAwsSecretKey = ML_AWS_SECRET_KEY
}

String cppCrossCompile = System.env.CPP_CROSS_COMPILE
if (cppCrossCompile == null) {
  if (project.hasProperty('CPP_CROSS_COMPILE')) {
    cppCrossCompile = CPP_CROSS_COMPILE
  } else {
    cppCrossCompile = ''
  }
}
if (cppCrossCompile != '' && cppCrossCompile != 'macosx' && cppCrossCompile != 'aarch64') {
  throw new GradleException("CPP_CROSS_COMPILE property must be empty, 'macosx' or 'aarch64'")
}

String osArch = System.properties['os.arch']
// Some versions of Java report hardware architectures that
// don't match other tools - these need to be normalized
if (osArch == 'amd64') {
  osArch = 'x86_64'
} else if (osArch == 'arm64') {
  osArch = 'aarch64'
}
String artifactClassifier
if (isWindows) {
  artifactClassifier = 'windows-x86_64'
} else if (isMacOsX || cppCrossCompile == 'macosx') {
  artifactClassifier = 'darwin-' + osArch
} else if (cppCrossCompile != '') {
  artifactClassifier = 'linux-' + cppCrossCompile
} else {
  artifactClassifier = 'linux-' + osArch
}

// Always do the C++ build using bash (Git bash on Windows)
project.ext.bash = isWindows ? "C:\\Program Files\\Git\\bin\\bash" : "/bin/bash"
project.ext.make = (isMacOsX || isWindows) ? "gnumake" : "make"
project.ext.numCpus = Runtime.runtime.availableProcessors()
project.ext.makeEnvironment = [ 'CPP_CROSS_COMPILE': cppCrossCompile,
                                'VERSION_QUALIFIER': versionQualifier,
                                'SNAPSHOT': (isSnapshot ? 'yes' : 'no'),
                                'ML_DEBUG': mlDebug ]

configurations.all {
  // check for updates every build
  resolutionStrategy.cacheChangingModulesFor 0, 'seconds'
}

task clean(type: Exec) {
  environment makeEnvironment
  commandLine bash
  args '-c', 'source ./set_env.sh && rm -rf build && ' + make + ' clean'
  workingDir "${projectDir}"
}

task compile(type: Exec) {
  // Only do this fully parallelised compile without linking step on a quad core
  // machine or better - with fewer cores it's not worth it
  enabled numCpus >= 4
  environment makeEnvironment
  commandLine bash
  args '-c', 'source ./set_env.sh && 3rd_party/pull-eigen.sh && ' + make + ' -j' + numCpus + ' objcompile'
  workingDir "${projectDir}"
}

task make(type: Exec) {
  environment makeEnvironment
  commandLine bash
  args '-c', 'source ./set_env.sh && ' + make + ' -j' + numCpus
  workingDir "${projectDir}"
  dependsOn 'compile'
}

task strip(type: Exec) {
  environment makeEnvironment
  commandLine bash
  args '-c', 'source ./set_env.sh && dev-tools/strip_binaries.sh'
  workingDir "${projectDir}"
  dependsOn 'make'
}

task format(type: Exec) {
  commandLine bash
  args '-c', 'source ./set_env.sh && dev-tools/clang-format.sh'
  workingDir "${projectDir}"
}

def zipSpec = copySpec {
  from("${buildDir}/distribution") {
    // Don't copy Windows import libraries
    exclude "**/*.lib"
    // Don't copy the test support library
    exclude "**/libMlTest.*"
    // Don't copy debug files
    exclude "**/*-debug"
    exclude "**/*.pdb"
    exclude "**/*.dSYM/**"
    // Don't copy core dumps
    exclude "**/core*"
    includeEmptyDirs = false
  }
}

task buildZip(type: Zip) {
  dependsOn strip
  archiveBaseName = artifactName
  with zipSpec
  destinationDirectory = file("${buildDir}/distributions")
  archiveVersion = project.version
  archiveClassifier = artifactClassifier
}

def zipSpecSymbols = copySpec {
  from("${buildDir}/distribution") {
    // only take debug files
    include "**/*-debug"
    include "**/*.pdb"
    include "**/*.dSYM/**"
    includeEmptyDirs = false
  }
}

task buildZipSymbols(type: Zip) {
  dependsOn strip
  archiveBaseName = "$artifactName-debug"
  with zipSpecSymbols
  destinationDirectory = file("${buildDir}/distributions")
  archiveVersion = project.version
  archiveClassifier = artifactClassifier
}

// The uber zip contains C++ binaries for as many platforms as possible
def uberZipSpec = copySpec {
  // We know we'll have binaries from the current build
  from(zipTree(buildZip.outputs.files.singleFile))
  // We might also have binaries for other platforms (e.g. if they've been built in Docker)
  def localZips = fileTree("${buildDir}/distributions").matching {
      include "${artifactName}-${project.version}-darwin-*.zip"
      include "${artifactName}-${project.version}-linux-*.zip"
      include "${artifactName}-${project.version}-windows-*.zip"
  }
  for (zipFile in localZips) {
    from(zipTree(zipFile)) {
      duplicatesStrategy 'exclude'
    }
  }
}

task buildUberZip(type: Zip) {
  dependsOn buildZip
  archiveBaseName = "$artifactName"
  with uberZipSpec
  destinationDirectory = file("${buildDir}/distributions")
  archiveVersion = project.version
}

configurations.create('default')

artifacts {
  'default' buildUberZip
}

String artifactGroupPath = project.group.replaceAll("\\.", "/")

task test(type: Exec) {
  environment makeEnvironment
  commandLine bash
  args '-c', 'source ./set_env.sh && ' + make + ' -j' + numCpus + ' test'
  workingDir "${projectDir}"
  dependsOn 'strip'
  description = 'Run C++ tests'
}

task check {
  dependsOn 'test'
  description = 'Run all verification tasks'
}

task assemble {
  dependsOn 'buildUberZip', 'buildZipSymbols'
  description = 'Assemble the C++ part of Machine Learning'
}

task build(dependsOn: [check, assemble]) {
  group = 'Build'
  description = 'Assemble and test the C++ part of Machine Learning'
}

/**
 * Gradle 6 gets confused if we try to use its standard dependency management to
 * convert artifacts with a classifier to an artifact for the same project
 * without a classifier.  Therefore this class uses low level functionality to
 * get the platform-specific artifacts.
 */
class DownloadPlatformSpecific extends DefaultTask {

  @Input
  String version = project.version

  @Input
  String artifactGroupPath = project.group.replaceAll("\\.", "/")

  /**
   * Base name for the artifacts
   */
  @Input
  String baseName

  /**
   * Directory to download platform specific zip files into
   */
  @Input
  String downloadDirectory

  /**
   * Directory to extract downloaded zip files into
   */
  @OutputDirectory
  File extractDirectory

  @Input
  List<String> platforms = [ 'darwin-aarch64', 'darwin-x86_64', 'linux-aarch64', 'linux-x86_64', 'windows-x86_64' ]

  DownloadPlatformSpecific() {
    // Always run this task, in case the platform-specific zips have changed
    outputs.upToDateWhen {
      return false
    }
  }

  @TaskAction
  void combine() {
    extractDirectory.deleteDir()
    platforms.each {
      File zipFile = new File(downloadDirectory, "${baseName}-${version}-${it}.zip")
      zipFile.parentFile.mkdirs()
      new URL("https://prelert-artifacts.s3.amazonaws.com/maven/${artifactGroupPath}/${baseName}/${version}/${zipFile.name}").withInputStream { i ->
        zipFile.withOutputStream { o ->
          o << i
        }
      }
      ZipFile zip = new ZipFile(zipFile)
      zip.entries().each {
        File target = new File(extractDirectory, it.name)
        // There can be overlaps between the platform-specific zips, so skip duplicates
        if (target.exists() == false) {
          if (it.isDirectory()) {
            target.mkdirs()
          } else {
            target.parentFile.mkdirs()
            target.withOutputStream { o ->
              o << zip.getInputStream(it)
            }
            target.setLastModified(it.getTime())
          }
        }
      }
      zip.close()
    }
  }
}

task downloadPlatformSpecific(type: DownloadPlatformSpecific) {
  baseName = artifactName
  downloadDirectory = "${buildDir}/distributions"
  extractDirectory = file("${buildDir}/temp")
  description = 'Download and extract previously created platform-specific C++ zips'
}

task buildUberZipFromDownloads(type: Zip, dependsOn: downloadPlatformSpecific) {
  archiveBaseName = artifactName
  archiveVersion = project.version
  destinationDirectory = file("${buildDir}/distributions")
  from(fileTree(downloadPlatformSpecific.outputs.files.singleFile))
  description = 'Create an uber zip from combined platform-specific C++ distributions'
}

task buildDependencyReport(type: Exec) {
  outputs.file("${buildDir}/distributions/dependencies.csv")
  environment makeEnvironment
  commandLine bash
  args '-c', "source ./set_env.sh && 3rd_party/dependency_report.sh --csv \"${outputs.files.singleFile}\""
  workingDir "${projectDir}"
  description = 'Create a CSV report on 3rd party dependencies we redistribute'
}

if (rootProject == project) {
  // The UploadS3Task is only expected to be available when ml-cpp is a
  // standalone project, not when it's in elasticsearch-extra.
  Class UploadS3Task = this.class.classLoader.loadClass("org.elastic.gradle.UploadS3Task")

  // This intentionally doesn't depend on assemble.
  // This gives us the flexibility to build in different
  // ways and still use the same upload code.
  task upload(type: UploadS3Task) {
    bucket 'prelert-artifacts'
    // Only upload the platform-specific artifacts in this task
    def zipFileDir = fileTree("${buildDir}/distributions").matching { include "*-aarch64.zip", "*-x86_64.zip" }
    for (zipFile in zipFileDir) {
      upload zipFile, "maven/${artifactGroupPath}/${artifactName}/${project.version}/${zipFile.name}"
    }
    description = 'Upload C++ zips to S3 Bucket'
  }

  task uberUpload(type: UploadS3Task, dependsOn: [buildUberZipFromDownloads, buildDependencyReport]) {
    bucket 'prelert-artifacts'
    upload buildUberZipFromDownloads.outputs.files.singleFile, "maven/${artifactGroupPath}/${artifactName}/${project.version}/${buildUberZipFromDownloads.outputs.files.singleFile.name}"
    upload buildDependencyReport.outputs.files.singleFile, "maven/${artifactGroupPath}/${artifactName}/${project.version}/${buildDependencyReport.outputs.files.singleFile.name}"
    description = 'Upload C++ uber zip and dependency report to S3 Bucket'
  }

  // The wrapper task also needs to be excluded when ml-cpp is in
  // elasticsearch-extra because it's only permitted in the root project.
  // See https://github.com/gradle/gradle/issues/5816 for more discussion on this.
  wrapper {
    distributionType = 'ALL'
    doLast {
      final DistributionLocator locator = new DistributionLocator()
      final GradleVersion version = GradleVersion.version(wrapper.gradleVersion)
      final URI distributionUri = locator.getDistributionFor(version, wrapper.distributionType.name().toLowerCase(Locale.ENGLISH))
      final URI sha256Uri = new URI(distributionUri.toString() + ".sha256")
      final String sha256Sum = new String(sha256Uri.toURL().bytes)
      wrapper.getPropertiesFile() << "distributionSha256Sum=${sha256Sum}\n"
      println "Added checksum to wrapper properties"
    }
  }
}
