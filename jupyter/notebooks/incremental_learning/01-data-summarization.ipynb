{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n",
    "# or more contributor license agreements. Licensed under the Elastic License;\n",
    "# you may not use this file except in compliance with the Elastic License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scenario 1: Data summarization\n",
    "\n",
    "1. Train model (M1) on the complete dataset (D1)\n",
    "\n",
    "2. Generate a summarization dataset using some technique (D2)\n",
    "\n",
    "3. Train a new model (M2) on D2\n",
    "    1. Use the same best hyperparameters as for M1   \n",
    "    2. **Identify a new set of best hyperparameters**\n",
    "    \n",
    "4. Compare M1 and M2\n",
    "    1. Evaluation M1 and M2 on the complete dataset D1.\n",
    "    2. Evaluate M1 and M2 on a grid and compute divergence\n",
    "    3. Compare feature importance vectors for individual data points from M1 and M2 (should be very similar)\n",
    "    4. Compare errors on the test dataset (D3)\n",
    "\n",
    "**Notes:**\n",
    "- We assume that generation of a summarization dataset is implemented. It can be written in Python for prototyping.\n",
    "- 4 can be done with an inference pipeline and eland\n",
    "- We need a simple way to query a model using inference pipeline (e.g. Python wrapper?)\n",
    "- Evaluations can also be done with sklearn?\n",
    "- What is the minimum amount of data we can get away with?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%config Completer.use_jedi = False\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import max_error, mean_absolute_error, mean_squared_error\n",
    "\n",
    "from incremental_learning.misc import train, summarize, update, evaluate\n",
    "from incremental_learning.config import datasets_dir, root_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Train model (M1) on the complete dataset (D1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "session: job_cyunr\tcommand:\n",
      "/home/valeriy/Documents/workspace/valeriy42/ml-cpp/build/distribution/platform/linux-x86_64/bin/data_frame_analyzer --input /tmp/tmpfx07d6__ --config /tmp/tmpfyw9hjjs --output /tmp/tmp_ektnwwe --persist /tmp/tmpt1_ks0s9; if [ $? -eq 0 ]; then echo \"Success\"; else echo \"Failure\";  fi;\n"
     ]
    }
   ],
   "source": [
    "dataset_name = 'ccpp'\n",
    "D1 = pd.read_csv(datasets_dir / '{}.csv'.format(dataset_name))\n",
    "D1.drop_duplicates(inplace=True)\n",
    "\n",
    "## sample 1000 rows just for test purposes!\n",
    "D1 = D1.sample(100)\n",
    "\n",
    "job1 = train(dataset_name, D1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><tr>\n",
       "                                                            <td width=\"50%\" style=\"text-align:center;\"><b>stderr</b></td>\n",
       "                                                            <td width=\"50%\" style=\"text-align:center;\"><b>output</b></td>\n",
       "                                                            </tr>\n",
       "                                                            <tr>\n",
       "                                                            <td width=\"50%\" style=\"text-align:left;\"><pre> /home/valeriy/Documents/workspace/valeriy42/ml-cpp/build/distribution/platform/linux-x86_64/bin/data_frame_analyzer --input /tmp/tmpfx07d6__ --config /tmp/tmpfyw9hjjs --output /tmp/tmp_ektnwwe --persist /tmp/tmpt1_ks0s9; if [ $? -eq 0 ]; then echo \"Success\"; else echo \"Failure\";  fi\n",
       "(env) ✔ ~/Documents/workspace/valeriy42/ml-cpp/jupyter/notebooks/evaluation_scenarios [python-tests L|●2✚ 2…2⚑ 6]\n",
       "14:59 $  /home/valeriy/Documents/workspace/valeriy42/ml-cpp/build/distribution/platform/linux-x86_64/bin/data_frame_analyzer --input /tmp/tmpfx07d6__ --config /tmp/tmpfyw9hjjs --output /tmp/tmp_ektnwwe --persist /tmp/tmpt1_ks0s9; if [ $? -eq 0 ]; then echo \"Success\"; else echo \"Failure\";  fi\n",
       "2021-06-28 12:59:21,801795 UTC [21278] DEBUG Main.cc@145 data_frame_analyzer (64 bit): Version 8.0.0-SNAPSHOT (Build 0833c91c67e7db) Copyright (c) 2021 Elasticsearch BV\n",
       "2021-06-28 12:59:21,801837 UTC [21278] DEBUG CProcessPriority_Linux.cc@33 Successfully increased OOM killer adjustment via /proc/self/oom_score_adj\n",
       "2021-06-28 12:59:21,801847 UTC [21278] DEBUG CSystemCallFilter_Linux.cc@128 Seccomp BPF filters available\n",
       "2021-06-28 12:59:21,802046 UTC [21278] DEBUG CSystemCallFilter_Linux.cc@154 Seccomp BPF installed\n",
       "2021-06-28 12:59:21,809309 UTC [21278] DEBUG CDataFrameAnalyzer.cc@102 Received 9527 rows\n",
       "2021-06-28 12:59:55,230202 UTC [21278] INFO  CBoostedTreeImpl.cc@260 Exiting hyperparameter optimisation loop early\n",
       "2021-06-28 12:59:58,053972 UTC [21278] INFO  Main.cc@248 [{\"name\":\"E_DFTPMEstimatedPeakMemoryUsage\",\"description\":\"The upfront estimate of the peak memory training the predictive model would use\",\"value\":27586043}\n",
       ",{\"name\":\"E_DFTPMPeakMemoryUsage\",\"description\":\"The peak memory training the predictive model used\",\"value\":14388224}\n",
       ",{\"name\":\"E_DFTPMTimeToTrain\",\"description\":\"The time it took to train the predictive model\",\"value\":35244}\n",
       ",{\"name\":\"E_DFTPMTrainedForestNumberTrees\",\"description\":\"The total number of trees in the trained forest\",\"value\":210}\n",
       "]\n",
       "2021-06-28 12:59:58,054004 UTC [21278] DEBUG Main.cc@253 ML data frame analyzer exiting\n",
       "Success\n",
       "(env) ✔ ~/Documents/workspace/valeriy42/ml-cpp/jupyter/notebooks/evaluation_scenarios [python-tests L|●2✚ 2…2⚑ 6]\n",
       "14:59 $</pre></td>\n",
       "                                                            <td width=\"50%\" style=\"text-align:left;\"><pre>,{\"row_results\":{\"checksum\":0,\"results\":{\"ml\":{\"PE_prediction\":464.3738708496094\n",
       ",{\"row_results\":{\"checksum\":0,\"results\":{\"ml\":{\"PE_prediction\":468.8424682617187\n",
       ",{\"row_results\":{\"checksum\":0,\"results\":{\"ml\":{\"PE_prediction\":459.07763671875,\"\n",
       ",{\"row_results\":{\"checksum\":0,\"results\":{\"ml\":{\"PE_prediction\":469.3031616210937\n",
       ",{\"row_results\":{\"checksum\":0,\"results\":{\"ml\":{\"PE_prediction\":429.9221496582031\n",
       ",{\"row_results\":{\"checksum\":0,\"results\":{\"ml\":{\"PE_prediction\":438.406982421875,\n",
       ",{\"row_results\":{\"checksum\":0,\"results\":{\"ml\":{\"PE_prediction\":452.0242919921875\n",
       ",{\"model_metadata\":{\"total_feature_importance\":[],\"hyperparameters\":[{\"name\":\"do\n",
       ",{\"compressed_data_summarization\":{\"doc_num\":0,\"data_summarization\":\"H4sIAAAAAAA\n",
       "]</pre></td>\n",
       "                                                            </tr>\n",
       "                                                    </table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " /home/valeriy/Documents/workspace/valeriy42/ml-cpp/build/distribution/platform/linux-x86_64/bin/data_frame_analyzer --input /tmp/tmpfx07d6__ --config /tmp/tmpfyw9hjjs --output /tmp/tmp_ektnwwe --persist /tmp/tmpt1_ks0s9; if [ $? -eq 0 ]; then echo \"Success\"; else echo \"Failure\";  fi\n",
      "(env) ✔ ~/Documents/workspace/valeriy42/ml-cpp/jupyter/notebooks/evaluation_scenarios [python-tests L|●2✚ 2…2⚑ 6]\n",
      "14:59 $  /home/valeriy/Documents/workspace/valeriy42/ml-cpp/build/distribution/platform/linux-x86_64/bin/data_frame_analyzer --input /tmp/tmpfx07d6__ --config /tmp/tmpfyw9hjjs --output /tmp/tmp_ektnwwe --persist /tmp/tmpt1_ks0s9; if [ $? -eq 0 ]; then echo \"Success\"; else echo \"Failure\";  fi\n",
      "2021-06-28 12:59:21,801795 UTC [21278] DEBUG Main.cc@145 data_frame_analyzer (64 bit): Version 8.0.0-SNAPSHOT (Build 0833c91c67e7db) Copyright (c) 2021 Elasticsearch BV\n",
      "2021-06-28 12:59:21,801837 UTC [21278] DEBUG CProcessPriority_Linux.cc@33 Successfully increased OOM killer adjustment via /proc/self/oom_score_adj\n",
      "2021-06-28 12:59:21,801847 UTC [21278] DEBUG CSystemCallFilter_Linux.cc@128 Seccomp BPF filters available\n",
      "2021-06-28 12:59:21,802046 UTC [21278] DEBUG CSystemCallFilter_Linux.cc@154 Seccomp BPF installed\n",
      "2021-06-28 12:59:21,809309 UTC [21278] DEBUG CDataFrameAnalyzer.cc@102 Received 9527 rows\n",
      "2021-06-28 12:59:55,230202 UTC [21278] INFO  CBoostedTreeImpl.cc@260 Exiting hyperparameter optimisation loop early\n",
      "2021-06-28 12:59:58,053972 UTC [21278] INFO  Main.cc@248 [{\"name\":\"E_DFTPMEstimatedPeakMemoryUsage\",\"description\":\"The upfront estimate of the peak memory training the predictive model would use\",\"value\":27586043}\n",
      ",{\"name\":\"E_DFTPMPeakMemoryUsage\",\"description\":\"The peak memory training the predictive model used\",\"value\":14388224}\n",
      ",{\"name\":\"E_DFTPMTimeToTrain\",\"description\":\"The time it took to train the predictive model\",\"value\":35244}\n",
      ",{\"name\":\"E_DFTPMTrainedForestNumberTrees\",\"description\":\"The total number of trees in the trained forest\",\"value\":210}\n",
      "]\n",
      "2021-06-28 12:59:58,054004 UTC [21278] DEBUG Main.cc@253 ML data frame analyzer exiting\n",
      "Success\n",
      "(env) ✔ ~/Documents/workspace/valeriy42/ml-cpp/jupyter/notebooks/evaluation_scenarios [python-tests L|●2✚ 2…2⚑ 6]\n",
      "14:59 $\n",
      "Job succeeded\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job1.wait_to_complete()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Generate a sumarization dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampling_method = 'random'\n",
    "D2 = summarize(dataset_name=dataset_name, dataset=D1,\n",
    "              size=0.25, model_definition=job1.get_model_definition(), \n",
    "              method=sampling_method, verbose=False, \n",
    "              dependent_variable=job1.dependent_variable)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "## 3. A. Train a new model with the same best best hyperparameters"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# TODO I need to inject hyperparameters here\n",
    "job2 = train(dataset_name, D2)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "job2.wait_to_complete()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "## 3. B. Train a new model with new best hyperparameters"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "job2 = train(dataset_name, D2)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "job2.wait_to_complete()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. C. Incremetally train a new model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "session: job_bllod\tcommand:\n",
      "/home/valeriy/Documents/workspace/valeriy42/ml-cpp/build/distribution/platform/linux-x86_64/bin/data_frame_analyzer --input /tmp/tmpirm6gxj9 --config /tmp/tmpuu53ifdr --output /tmp/tmptt1nhpbl --restore /tmp/tmp5q0rnxem; if [ $? -eq 0 ]; then echo \"Success\"; else echo \"Failure\";  fi;\n"
     ]
    }
   ],
   "source": [
    "job2 = update(dataset_name, D2, job1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><tr>\n",
       "                                                            <td width=\"50%\" style=\"text-align:center;\"><b>stderr</b></td>\n",
       "                                                            <td width=\"50%\" style=\"text-align:center;\"><b>output</b></td>\n",
       "                                                            </tr>\n",
       "                                                            <tr>\n",
       "                                                            <td width=\"50%\" style=\"text-align:left;\"><pre> /home/valeriy/Documents/workspace/valeriy42/ml-cpp/build/distribution/platform/linux-x86_64/bin/data_frame_analyzer --input /tmp/tmpirm6gxj9 --config /tmp/tmpuu53ifdr --output /tmp/tmptt1nhpbl --restore /tmp/tmp5q0rnxem; if [ $? -eq 0 ]; then echo \"Success\"; else echo \"Failure\";  fi\n",
       "(env) ✔ ~/Documents/workspace/valeriy42/ml-cpp/jupyter/notebooks/evaluation_scenarios [python-tests L|●2✚ 2…2⚑ 6]\n",
       "15:01 $  /home/valeriy/Documents/workspace/valeriy42/ml-cpp/build/distribution/platform/linux-x86_64/bin/data_frame_analyzer --input /tmp/tmpirm6gxj9 --config /tmp/tmpuu53ifdr --output /tmp/tmptt1nhpbl --restore /tmp/tmp5q0rnxem; if [ $? -eq 0 ]; then echo \"Success\"; else echo \"Failure\";  fi\n",
       "2021-06-28 13:01:00,038082 UTC [29239] DEBUG Main.cc@145 data_frame_analyzer (64 bit): Version 8.0.0-SNAPSHOT (Build 0833c91c67e7db) Copyright (c) 2021 Elasticsearch BV\n",
       "2021-06-28 13:01:00,038123 UTC [29239] DEBUG CProcessPriority_Linux.cc@33 Successfully increased OOM killer adjustment via /proc/self/oom_score_adj\n",
       "2021-06-28 13:01:00,038133 UTC [29239] DEBUG CSystemCallFilter_Linux.cc@128 Seccomp BPF filters available\n",
       "2021-06-28 13:01:00,039183 UTC [29239] DEBUG CSystemCallFilter_Linux.cc@154 Seccomp BPF installed\n",
       "2021-06-28 13:01:01,266902 UTC [29239] DEBUG CDataFrameAnalyzer.cc@102 Received 3333 rows\n",
       "2021-06-28 13:01:02,263974 UTC [29239] INFO  Main.cc@248 [{\"name\":\"E_DFTPMEstimatedPeakMemoryUsage\",\"description\":\"The upfront estimate of the peak memory training the predictive model would use\",\"value\":23511218}\n",
       ",{\"name\":\"E_DFTPMPeakMemoryUsage\",\"description\":\"The peak memory training the predictive model used\",\"value\":7897926}\n",
       ",{\"name\":\"E_DFTPMTimeToTrain\",\"description\":\"The time it took to train the predictive model\",\"value\":280}\n",
       "]\n",
       "2021-06-28 13:01:02,264005 UTC [29239] DEBUG Main.cc@253 ML data frame analyzer exiting\n",
       "Success\n",
       "(env) ✔ ~/Documents/workspace/valeriy42/ml-cpp/jupyter/notebooks/evaluation_scenarios [python-tests L|●2✚ 2…2⚑ 6]\n",
       "15:01 $</pre></td>\n",
       "                                                            <td width=\"50%\" style=\"text-align:left;\"><pre>,{\"row_results\":{\"checksum\":0,\"results\":{\"ml\":{\"PE_prediction\":440.5562133789062\n",
       ",{\"row_results\":{\"checksum\":0,\"results\":{\"ml\":{\"PE_prediction\":463.5453186035156\n",
       ",{\"row_results\":{\"checksum\":0,\"results\":{\"ml\":{\"PE_prediction\":470.7997436523437\n",
       ",{\"row_results\":{\"checksum\":0,\"results\":{\"ml\":{\"PE_prediction\":434.1181945800781\n",
       ",{\"row_results\":{\"checksum\":0,\"results\":{\"ml\":{\"PE_prediction\":434.8784790039062\n",
       ",{\"row_results\":{\"checksum\":0,\"results\":{\"ml\":{\"PE_prediction\":446.3300170898437\n",
       ",{\"row_results\":{\"checksum\":0,\"results\":{\"ml\":{\"PE_prediction\":444.5942993164062\n",
       ",{\"model_metadata\":{\"total_feature_importance\":[],\"hyperparameters\":[{\"name\":\"do\n",
       ",{\"compressed_data_summarization\":{\"doc_num\":0,\"data_summarization\":\"H4sIAAAAAAA\n",
       "]</pre></td>\n",
       "                                                            </tr>\n",
       "                                                    </table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " /home/valeriy/Documents/workspace/valeriy42/ml-cpp/build/distribution/platform/linux-x86_64/bin/data_frame_analyzer --input /tmp/tmpirm6gxj9 --config /tmp/tmpuu53ifdr --output /tmp/tmptt1nhpbl --restore /tmp/tmp5q0rnxem; if [ $? -eq 0 ]; then echo \"Success\"; else echo \"Failure\";  fi\n",
      "(env) ✔ ~/Documents/workspace/valeriy42/ml-cpp/jupyter/notebooks/evaluation_scenarios [python-tests L|●2✚ 2…2⚑ 6]\n",
      "15:01 $  /home/valeriy/Documents/workspace/valeriy42/ml-cpp/build/distribution/platform/linux-x86_64/bin/data_frame_analyzer --input /tmp/tmpirm6gxj9 --config /tmp/tmpuu53ifdr --output /tmp/tmptt1nhpbl --restore /tmp/tmp5q0rnxem; if [ $? -eq 0 ]; then echo \"Success\"; else echo \"Failure\";  fi\n",
      "2021-06-28 13:01:00,038082 UTC [29239] DEBUG Main.cc@145 data_frame_analyzer (64 bit): Version 8.0.0-SNAPSHOT (Build 0833c91c67e7db) Copyright (c) 2021 Elasticsearch BV\n",
      "2021-06-28 13:01:00,038123 UTC [29239] DEBUG CProcessPriority_Linux.cc@33 Successfully increased OOM killer adjustment via /proc/self/oom_score_adj\n",
      "2021-06-28 13:01:00,038133 UTC [29239] DEBUG CSystemCallFilter_Linux.cc@128 Seccomp BPF filters available\n",
      "2021-06-28 13:01:00,039183 UTC [29239] DEBUG CSystemCallFilter_Linux.cc@154 Seccomp BPF installed\n",
      "2021-06-28 13:01:01,266902 UTC [29239] DEBUG CDataFrameAnalyzer.cc@102 Received 3333 rows\n",
      "2021-06-28 13:01:02,263974 UTC [29239] INFO  Main.cc@248 [{\"name\":\"E_DFTPMEstimatedPeakMemoryUsage\",\"description\":\"The upfront estimate of the peak memory training the predictive model would use\",\"value\":23511218}\n",
      ",{\"name\":\"E_DFTPMPeakMemoryUsage\",\"description\":\"The peak memory training the predictive model used\",\"value\":7897926}\n",
      ",{\"name\":\"E_DFTPMTimeToTrain\",\"description\":\"The time it took to train the predictive model\",\"value\":280}\n",
      "]\n",
      "2021-06-28 13:01:02,264005 UTC [29239] DEBUG Main.cc@253 ML data frame analyzer exiting\n",
      "Success\n",
      "(env) ✔ ~/Documents/workspace/valeriy42/ml-cpp/jupyter/notebooks/evaluation_scenarios [python-tests L|●2✚ 2…2⚑ 6]\n",
      "15:01 $\n",
      "Job succeeded\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job2.wait_to_complete()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. A. Compare M1 and M2 on D1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation failed\n"
     ]
    }
   ],
   "source": [
    "y_true = D1[job1.dependent_variable]\n",
    "y_M1 = job1.get_predictions()\n",
    "eval_job = evaluate(dataset_name, D1, job2)\n",
    "success = eval_job.wait_to_complete()\n",
    "if not success:\n",
    "    print('Evaluation failed')\n",
    "y_M2 = eval_job.get_predictions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(ytrue, m1pred, m2pred):\n",
    "    m1_mae = mean_absolute_error(ytrue, m1pred)\n",
    "    m1_mse = mean_squared_error(ytrue, m1pred)\n",
    "    m2_mae = mean_absolute_error(ytrue, m2pred)\n",
    "    m2_mse = mean_squared_error(ytrue, m2pred)\n",
    "    print(\"M1: MAE: {}\\tMSE:{}\".format(m1_mae, m1_mse))\n",
    "    print(\"M2: MAE: {}\\tMSE:{}\".format(m2_mae, m2_mse))\n",
    "    ax = sns.scatterplot(x=m1pred, y=m2pred)\n",
    "    plt.xlabel('M1 predictions')\n",
    "    plt.ylabel('M2 predictions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_metrics(y_true, y_M1, y_M2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "cd811bcf3f365bc5382730ef97b333cd6ca82417629bc5a6815cfad2f5503789"
  },
  "kernelspec": {
   "display_name": "Python 3.6.9 64-bit ('env': venv)",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}