{
 "cells": [
  {
   "cell_type": "raw",
   "id": "54eca0dd",
   "metadata": {},
   "source": [
    "# Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n",
    "# or more contributor license agreements. Licensed under the Elastic License\n",
    "# 2.0 and the following additional limitation. Functionality enabled by the\n",
    "# files subject to the Elastic License 2.0 may only be used in production when\n",
    "# invoked by an Elasticsearch process with a license key installed that permits\n",
    "# use of machine learning features. You may not use this file except in\n",
    "# compliance with the Elastic License 2.0 and the foregoing additional\n",
    "# limitation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bfe7759",
   "metadata": {},
   "source": [
    "# Incremental Learning 3: Benchmark incremental learning algorithm with transformed data\n",
    "\n",
    "1. Train model (M1) on the complete dataset (D1).\n",
    "2. Split the complete dataset (D1) into the base dataset (D2) and the update dataset (D3).\n",
    "3. Train a new model (M2) on D2 and update it using D3.\n",
    "4. Compare M1 and M2\n",
    "    1. Evaluation M1 and M2 on the complete dataset D1.\n",
    "    2. TODO: Compare feature importance vectors for individual data points from M1 and M2 (should be very similar)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "eb69444d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%config Completer.use_jedi = False\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "import pprint\n",
    "\n",
    "from incremental_learning.config import jobs_dir, logger\n",
    "from incremental_learning.job import train, update, evaluate\n",
    "from incremental_learning.storage import read_dataset, upload_job, delete_job\n",
    "from incremental_learning.transforms import transform_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80c9db75",
   "metadata": {},
   "source": [
    "## 1. Train model (M1) on the complete dataset (D1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e2e3fc09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_regression_metrics(y_true,\n",
    "                               baseline_model_predictions,\n",
    "                               trained_model_predictions,\n",
    "                               updated_model_predictions):\n",
    "    scores = {\n",
    "        'baseline': {\n",
    "            'mae': metrics.mean_absolute_error(y_true, baseline_model_predictions),\n",
    "            'mse': metrics.mean_squared_error(y_true, baseline_model_predictions)\n",
    "        },\n",
    "        'trained_model': {\n",
    "            'mae': metrics.mean_absolute_error(y_true, trained_model_predictions),\n",
    "            'mse': metrics.mean_squared_error(y_true, trained_model_predictions)\n",
    "        },\n",
    "        'updated_model': {\n",
    "            'mae': metrics.mean_absolute_error(y_true, updated_model_predictions),\n",
    "            'mse': metrics.mean_squared_error(y_true, updated_model_predictions)\n",
    "        },\n",
    "    }\n",
    "    return scores\n",
    "\n",
    "\n",
    "def compute_classification_metrics(y_true,\n",
    "                                   baseline_model_predictions,\n",
    "                                   trained_model_predictions,\n",
    "                                   updated_model_predictions):\n",
    "    scores = {\n",
    "        'baseline': {\n",
    "            'acc': metrics.accuracy_score(y_true, baseline_model_predictions)\n",
    "        },\n",
    "        'trained_model': {\n",
    "            'acc': metrics.accuracy_score(y_true, trained_model_predictions)\n",
    "        },\n",
    "        'updated_model': {\n",
    "            'acc': metrics.accuracy_score(y_true, updated_model_predictions)\n",
    "        },\n",
    "    }\n",
    "\n",
    "    for label in np.unique(y_true):\n",
    "        scores['baseline']['precision_' + label] = \\\n",
    "            metrics.precision_score(y_true, baseline_model_predictions, pos_label=label)\n",
    "        scores['trained_model']['precision_' + label] = \\\n",
    "            metrics.precision_score(y_true, trained_model_predictions, pos_label=label)\n",
    "        scores['updated_model']['precision_' + label] = \\\n",
    "            metrics.precision_score(y_true, updated_model_predictions, pos_label=label)\n",
    "        scores['baseline']['recall_' + label] = \\\n",
    "            metrics.recall_score(y_true, baseline_model_predictions, pos_label=label)\n",
    "        scores['trained_model']['recall_' + label] = \\\n",
    "            metrics.recall_score(y_true, trained_model_predictions, pos_label=label)\n",
    "        scores['updated_model']['recall_' + label] = \\\n",
    "            metrics.recall_score(y_true, updated_model_predictions, pos_label=label)\n",
    "\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c0173d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_fraction = 0.2\n",
    "config = {\n",
    "    \"dataset_name\": \"ccpp\",\n",
    "    \"seed\": 90982247,\n",
    "    \"threads\": 1,\n",
    "    \"transform_name\": \"partition_on_metric_ranges\",\n",
    "    \"transform_parameters\": {\n",
    "        \"fraction\": 0.45,\n",
    "        \"metric_features\": [\n",
    "                    \"AT\",\n",
    "                    \"AP\"\n",
    "        ]\n",
    "    }\n",
    "}\n",
    "dataset_name = config['dataset_name']\n",
    "verbose=False\n",
    "force_update = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4a3be15e",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_dataset = read_dataset(config['dataset_name'])\n",
    "original_dataset = original_dataset.sample(frac=0.1)\n",
    "train_dataset, update_dataset, test1_dataset, test2_dataset = transform_dataset(dataset=original_dataset,\n",
    "                                                                                test_fraction=test_fraction,\n",
    "                                                                                transform_name=config['transform_name'],\n",
    "                                                                                transform_parameters=config[\n",
    "                                                                                    'transform_parameters'],\n",
    "                                                                                seed=config['seed'])\n",
    "baseline_dataset = pd.concat([train_dataset, update_dataset])\n",
    "test_dataset = pd.concat([test1_dataset, test2_dataset])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "262d8521",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I] incremental_learning >> Elapsed time: 176.3931188583374\n"
     ]
    }
   ],
   "source": [
    "baseline_model = train(config['dataset_name'], baseline_dataset, verbose=verbose)\n",
    "elapsed_time = baseline_model.wait_to_complete()\n",
    "logger.info('Elapsed time: {}'.format(elapsed_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d2b7ca69",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I] incremental_learning >> Elapsed time: 126.05649495124817\n"
     ]
    }
   ],
   "source": [
    "trained_model = train(dataset_name, train_dataset, verbose=verbose)\n",
    "elapsed_time = trained_model.wait_to_complete()\n",
    "logger.info('Elapsed time: {}'.format(elapsed_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "425b0032",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I] incremental_learning >> Elapsed time: 5.320300340652466\n"
     ]
    }
   ],
   "source": [
    "updated_model = update(dataset_name, update_dataset, trained_model, force=force_update, verbose=verbose)\n",
    "elapsed_time = updated_model.wait_to_complete()\n",
    "logger.info('Elapsed time: {}'.format(elapsed_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4624426f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.257479667663574"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_eval = evaluate(dataset_name, test_dataset, baseline_model, verbose=verbose)\n",
    "baseline_eval.wait_to_complete()\n",
    "\n",
    "trained_model_eval = evaluate(dataset_name, test_dataset, trained_model, verbose=verbose)\n",
    "trained_model_eval.wait_to_complete()\n",
    "\n",
    "updated_model_eval = evaluate(dataset_name, test_dataset, updated_model, verbose=verbose)\n",
    "updated_model_eval.wait_to_complete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d07ae267",
   "metadata": {},
   "outputs": [],
   "source": [
    "dependent_variable = baseline_model.dependent_variable\n",
    "\n",
    "scores = {}\n",
    "\n",
    "if baseline_model.is_regression():\n",
    "    y_true = np.array([y for y in test_dataset[dependent_variable]])\n",
    "    scores = compute_regression_metrics(y_true,\n",
    "                                        baseline_eval.get_predictions(),\n",
    "                                        trained_model_eval.get_predictions(),\n",
    "                                        updated_model_eval.get_predictions())\n",
    "elif baseline_model.is_classification():\n",
    "    y_true = np.array([str(y) for y in test_dataset[dependent_variable]])\n",
    "    scores = compute_classification_metrics(y_true,\n",
    "                                            baseline_eval.get_predictions(),\n",
    "                                            trained_model_eval.get_predictions(),\n",
    "                                            updated_model_eval.get_predictions())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "76ad2c91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'baseline': {'mae': 3.4624664751688647, 'mse': 21.21438482287693},\n",
      " 'trained_model': {'mae': 4.137316767374676, 'mse': 29.138932961441892},\n",
      " 'updated_model': {'mae': 3.6626670138041177, 'mse': 23.4148928431643}}\n"
     ]
    }
   ],
   "source": [
    "pprint.pprint(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7f9386cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = jobs_dir/'demo_baseline_model'\n",
    "baseline_model.store(destination=path)\n",
    "success = upload_job(local_job_path=path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2ca3a231",
   "metadata": {},
   "outputs": [],
   "source": [
    "delete_job('demo_baseline_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f139e8e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "bbee7842ce8ba476870a006d5d5b68f11cea175afb0fea017b7f81beccf88892"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
