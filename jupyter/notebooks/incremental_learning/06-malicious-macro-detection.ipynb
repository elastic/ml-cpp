{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b1d9d324",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n",
    "# or more contributor license agreements. Licensed under the Elastic License\n",
    "# 2.0 and the following additional limitation. Functionality enabled by the\n",
    "# files subject to the Elastic License 2.0 may only be used in production when\n",
    "# invoked by an Elasticsearch process with a license key installed that permits\n",
    "# use of machine learning features. You may not use this file except in\n",
    "# compliance with the Elastic License 2.0 and the foregoing additional\n",
    "# limitation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be1051de",
   "metadata": {},
   "source": [
    "## Improving Malicious Macro Detection with False Positive Telemetry\n",
    "\n",
    "1. Train a malicious macro detection model\n",
    "2. Test the performance of this base model on the False Positives dataset\n",
    "3. Incrementally updatee base model with False Positive Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "534da4f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%config Completer.use_jedi = False\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import datetime\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "from incremental_learning.config import datasets_dir, root_dir, jobs_dir\n",
    "from incremental_learning.job import update, evaluate, Job, train\n",
    "from incremental_learning.storage import download_dataset, download_job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7a64b50d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions(model: Job):\n",
    "    probabilities = model.get_probabilities()\n",
    "    predictions = np.array(list(map(lambda row: max(row, key=row.get), probabilities)))\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "98eb1749",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_dataset_name = 'base_macro_model_bool'\n",
    "download_dataset(full_dataset_name)\n",
    "D = pd.read_csv(datasets_dir / '{}.csv'.format(full_dataset_name))\n",
    "D.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a725257",
   "metadata": {},
   "source": [
    "### Calculate class counts for malicious and benign macros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bfa792bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    423245\n",
       "True     180167\n",
       "Name: malicious, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D['malicious'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2df06fd4",
   "metadata": {},
   "source": [
    "### Split the base dataset into test and train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eb6bd581",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_train, base_test = train_test_split(D, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "654873fa",
   "metadata": {},
   "source": [
    "### Get the Telemetry (Update) Dataset\n",
    "(note: the update dataset consist of benign example, ie. for all malicious=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cdf05e29",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-04 12:55:38,105 [I] incremental_learning >> File /root/data/configs/telemetry_fp_full.json does not exist.\n",
      "2022-03-04 12:55:38,178 [I] incremental_learning >> Downloading configs/telemetry_fp_full.json from the Google storage bucket to /root/data/configs/telemetry_fp_full.json.\n",
      "2022-03-04 12:55:38,310 [I] incremental_learning >> Retrieving datasets/telemetry_fp_full.csv from the Google storage bucket to /root/data/datasets/telemetry_fp_full.csv.\n"
     ]
    }
   ],
   "source": [
    "update_dataset_name = 'telemetry_fp_full'\n",
    "download_dataset(update_dataset_name)\n",
    "U = pd.read_csv(datasets_dir / '{}.csv'.format(update_dataset_name))\n",
    "U.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "291db98c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1670"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# after deduplication, we only have 1670 vectors available for update\n",
    "len(U)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b99ec8b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    1670\n",
       "Name: malicious, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# all of the examples in the false positives telemetry are benign, so malicious=False\n",
    "U['malicious'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f82aa539",
   "metadata": {},
   "source": [
    "### Split the update dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ba465d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "telemetry_train, telemetry_test = train_test_split(U, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7182342a",
   "metadata": {},
   "source": [
    "### Train base macro model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1aa666e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-04 14:17:10,315 [I] incremental_learning >> Downloading jobs/macro_baseline_model from the Google storage bucket to /root/data/jobs/macro_baseline_model.\n"
     ]
    }
   ],
   "source": [
    "# since we already have a pre-trained job, let's load that from the cloud bucket\n",
    "baseline_model_name = 'macro_baseline_model'\n",
    "download_job(baseline_model_name)\n",
    "job1 = Job.from_file(source=jobs_dir / 'macro_baseline_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5435cf12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "session: job_lbket/tmp/tmpd2vim5eq\tcommand:\n",
      "/ml-cpp/bin/data_frame_analyzer --input /tmp/tmps0i_ccwo --config /tmp/tmpd2vim5eq --output /tmp/tmpuobx8o47 --validElasticLicenseKeyConfirmed true --persist /tmp/tmp3kxyyj34; if [ $? -eq 0 ]; then echo \"Success\"; else echo \"Failure\";  fi;\n"
     ]
    }
   ],
   "source": [
    "# if you don't have a pre-trained base-macro model, uncomment the lines in cells below and run the job\n",
    "# job1 = train(full_dataset_name, base_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2e5c6c50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><tr>\n",
       "                                                                <td width=\"50%\" style=\"text-align:center;\"><b>stderr</b></td>\n",
       "                                                                <td width=\"50%\" style=\"text-align:center;\"><b>output</b></td>\n",
       "                                                                </tr>\n",
       "                                                                <tr>\n",
       "                                                                <td width=\"50%\" style=\"text-align:left;\"><pre>,{\"name\":\"E_DFTPMPeakMemoryUsage\",\"description\":\"The peak memory training the pr\n",
       "edictive model used\",\"value\":1052650400}\n",
       ",{\"name\":\"E_DFTPMTimeToTrain\",\"description\":\"The time it took to train the predi\n",
       "ctive model\",\"value\":4024706}\n",
       ",{\"name\":\"E_DFTPMTrainedForestNumberTrees\",\"description\":\"The total number of tr\n",
       "ees in the trained forest\",\"value\":574}\n",
       "]\n",
       "2022-03-03 23:31:01,709453 UTC [483] DEBUG Main.cc@265 ML data frame analyzer ex\n",
       "iting\n",
       "Success\n",
       "[root@ml-camilla-jupyter-mlcpp-large incremental_learning]#</pre></td>\n",
       "                                                                <td width=\"50%\" style=\"text-align:left;\"><pre>,{\"row_results\":{\"checksum\":0,\"results\":{\"ml\":{\"malicious_prediction\":\"True\",\"pr\n",
       ",{\"row_results\":{\"checksum\":0,\"results\":{\"ml\":{\"malicious_prediction\":\"True\",\"pr\n",
       ",{\"row_results\":{\"checksum\":0,\"results\":{\"ml\":{\"malicious_prediction\":\"False\",\"p\n",
       ",{\"row_results\":{\"checksum\":0,\"results\":{\"ml\":{\"malicious_prediction\":\"False\",\"p\n",
       ",{\"row_results\":{\"checksum\":0,\"results\":{\"ml\":{\"malicious_prediction\":\"False\",\"p\n",
       ",{\"row_results\":{\"checksum\":0,\"results\":{\"ml\":{\"malicious_prediction\":\"False\",\"p\n",
       ",{\"row_results\":{\"checksum\":0,\"results\":{\"ml\":{\"malicious_prediction\":\"True\",\"pr\n",
       ",{\"model_metadata\":{\"total_feature_importance\":[],\"hyperparameters\":[{\"name\":\"do\n",
       ",{\"compressed_data_summarization\":{\"doc_num\":0,\"data_summarization\":\"H4sIAAAAAAA\n",
       "]</pre></td>\n",
       "                                                                </tr>\n",
       "                                                        </table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job succeeded\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4052.1752047538757"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# job1.wait_to_complete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7a3ec851",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you want to store the results of the job, please uncomment and run this line\n",
    "# job1.store(jobs_dir / 'Macro_base')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d017ab6",
   "metadata": {},
   "source": [
    "### Check base model performance on base test set\n",
    "This is a quick check to see how well the model does on its own test data before update with telemetry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "69820c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_base_model_on_test = evaluate(full_dataset_name, base_test, job1, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6b8b6465",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time 0:00:30.515148\n"
     ]
    }
   ],
   "source": [
    "elapsed_time = eval_base_model_on_test.wait_to_complete()\n",
    "print('Elapsed time {}'.format(datetime.timedelta(seconds=elapsed_time)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a987684e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_base_test = get_predictions(eval_base_model_on_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f11f3707",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true_base = pd.array(base_test[job1.dependent_variable].astype(str))\n",
    "base_test_accuracy = accuracy_score(y_true_base, y_base_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f39b96cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7762899497029407"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_test_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "893db02e",
   "metadata": {},
   "source": [
    "### Check base model performance on telemetry false positives\n",
    "Please note that to evaluate the base model performance on the telemetry dataset, we will be using the whole telemetry dataset stored in the variable \"U\" and not the test/train splits of the telemetry dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c9e610e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_base_model_on_telemetry = evaluate(update_dataset_name, U, job1, verbose=False)\n",
    "elapsed_time = eval_base_model_on_telemetry.wait_to_complete()\n",
    "y_base_telemetry = get_predictions(eval_base_model_on_telemetry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8b0df487",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true_telemetry = pd.array(U[job1.dependent_variable].astype(str))\n",
    "base_telemetry_accuracy = accuracy_score(y_true_telemetry, y_base_telemetry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0188109c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7826347305389222"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_telemetry_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf390dc2",
   "metadata": {},
   "source": [
    "### Update baseline model with false positives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "18ece3d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters = job1.get_hyperparameters()\n",
    "del hyperparameters['retrained_tree_eta']\n",
    "job2 = update(update_dataset_name, telemetry_train, job1, verbose=False, hyperparameter_overrides=hyperparameters)\n",
    "elapsed_time = job2.wait_to_complete()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ecd64a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment this line if you want to store the model locally\n",
    "# job2.store(jobs_dir / 'macro_updated_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aa57d0c",
   "metadata": {},
   "source": [
    "### Evaluate Updated Telemetry Macro Model with Telemetry Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "21a1da33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time 0:00:05.787311\n"
     ]
    }
   ],
   "source": [
    "eval_updated_model_on_telemetry = evaluate(update_dataset_name, telemetry_test, job2, verbose=False)\n",
    "elapsed_time = eval_updated_model_on_telemetry.wait_to_complete()\n",
    "print('Elapsed time {}'.format(datetime.timedelta(seconds=elapsed_time)))\n",
    "y_job2 = get_predictions(eval_updated_model_on_telemetry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c072c2f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = pd.array(telemetry_test[job1.dependent_variable].astype(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d5665e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "job2_accuracy = accuracy_score(y_true, y_job2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9048ebd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job2_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32181e04",
   "metadata": {},
   "source": [
    "### Evaluate Updated Macro Model on Base Model Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c4762a81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time 0:00:16.145269\n"
     ]
    }
   ],
   "source": [
    "eval_updated_model_on_base_test = evaluate(update_dataset_name, base_test, job2, verbose=False)\n",
    "elapsed_time = eval_updated_model_on_base_test.wait_to_complete()\n",
    "print('Elapsed time {}'.format(datetime.timedelta(seconds=elapsed_time)))\n",
    "y_job2_base_test = get_predictions(eval_updated_model_on_base_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4d544004",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7756353421774401"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "updated_model_accuracy_on_base_test = accuracy_score(y_true_base, y_job2_base_test)\n",
    "updated_model_accuracy_on_base_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "455212bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4607e843",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
