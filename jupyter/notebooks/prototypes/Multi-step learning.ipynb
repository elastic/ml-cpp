{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "38a6d896",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%config Completer.use_jedi = False\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import namedtuple\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from incremental_learning.storage import read_dataset, upload_job \n",
    "from incremental_learning.job import train, update, evaluate, Job\n",
    "from incremental_learning.config import jobs_dir, logger\n",
    "from sklearn.metrics import mean_squared_error\n",
    "logger.setLevel(\"ERROR\")\n",
    "import time\n",
    "import diversipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d799a2f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "Run = namedtuple(\"Run\",[\"config\", \"run_logger\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "40954052",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a mock-up Run object with configurations similar to those used in the sacred library.\n",
    "run = Run(config={'threads':8, 'analysis':{'parameters':\n",
    "                                           {'tree_topology_change_penalty': 0.0, \n",
    "                                            'prediction_change_cost': 0.0,\n",
    "                                            'data_summarization_fraction': 1.0}}}, \n",
    "          run_logger=logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "711d4886",
   "metadata": {},
   "outputs": [],
   "source": [
    "# usual data wrangling. We are going to train and update using samples from train_dataset and evaluate\n",
    "# error on the test_dataset.\n",
    "\n",
    "dataset_name = 'house'\n",
    "original_dataset = read_dataset(dataset_name)\n",
    "\n",
    "test_fraction = 0.2\n",
    "training_fraction = 0.1\n",
    "update_fraction = 0.1\n",
    "\n",
    "train_dataset, test_dataset = train_test_split(original_dataset, test_size=test_fraction)\n",
    "train_dataset = train_dataset.copy()\n",
    "test_dataset = test_dataset.copy()\n",
    "\n",
    "baseline_dataset = train_dataset.sample(frac=training_fraction)\n",
    "update_num_samples = int(train_dataset.shape[0]*update_fraction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "10f45111",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25.25991916656494"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train the first job\n",
    "job1 = train(dataset_name, baseline_dataset, run=run, verbose=False)\n",
    "job1.wait_to_complete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7a81b8c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# optionally store/upload the job file for expensive jobs\n",
    "job_name = \"{}_basejob\".format(dataset_name)\n",
    "job_path = jobs_dir / job_name\n",
    "job1.store(job_path)\n",
    "# upload_job(job_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "930cc10d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_test_error(job):\n",
    "    dataset = test_dataset\n",
    "    job_eval = evaluate(dataset_name=dataset_name, dataset=dataset, original_job=job, run=run, verbose=False)\n",
    "    job_eval.wait_to_complete()\n",
    "    predictions = job_eval.get_predictions()\n",
    "\n",
    "    mse= mean_squared_error(dataset[job_eval.dependent_variable], predictions)\n",
    "    return mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f133e529",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_residuals(job):\n",
    "    dataset = train_dataset\n",
    "    job_eval = evaluate(dataset_name=dataset_name, dataset=dataset, original_job=job, run=run, verbose=False)\n",
    "    job_eval.wait_to_complete()\n",
    "    predictions = job_eval.get_predictions()\n",
    "    residuals = np.absolute(dataset[job_eval.dependent_variable] - predictions)\n",
    "    return residuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b37f2621",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mse: 1.279372e+09\n"
     ]
    }
   ],
   "source": [
    "# First test error\n",
    "print(\"mse: {:e}\".format(compute_test_error(job1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bea824b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: 1.375783e+09\n",
      "2: 1.425051e+09\n"
     ]
    }
   ],
   "source": [
    "# conduct 3 update steps and evaluate the test error\n",
    "job_prev = job1\n",
    "for step in range(1,4):\n",
    "    \n",
    "    # here we select 3 times of update_num_sample largest examples and then diverify using the \n",
    "    # same number update_num_sample to ensure that the update examples do not cluster in the same region.\n",
    "    train_dataset['indicator'] = get_residuals(job_prev)\n",
    "    largest = train_dataset.nlargest(n=3*update_num_samples, columns=['indicator'])\n",
    "    largest.drop(columns=['indicator'], inplace=True)\n",
    "    train_dataset.drop(columns=['indicator'], inplace=True)\n",
    "    dupdate = diversipy.subset.psa_select(largest.to_numpy(), update_num_samples)\n",
    "    D_update = pd.DataFrame(\n",
    "            data=dupdate, columns=largest.columns)\n",
    "\n",
    "\n",
    "\n",
    "    job_update = update(dataset_name=dataset_name, dataset=D_update, original_job=job_prev, \n",
    "                        run=run, verbose=False, force=True)\n",
    "    job_update.wait_to_complete()\n",
    "    \n",
    "    print(\"{}: {:e}\".format(step, compute_test_error(job_update)))\n",
    "    job_prev = job_update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09197dbe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
