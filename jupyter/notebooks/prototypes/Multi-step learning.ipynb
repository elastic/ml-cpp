{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "38a6d896",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%config Completer.use_jedi = False\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import namedtuple\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from incremental_learning.storage import read_dataset, upload_job \n",
    "from incremental_learning.job import train, update, evaluate, Job\n",
    "from incremental_learning.config import jobs_dir, logger\n",
    "from sklearn.metrics import mean_squared_error\n",
    "logger.setLevel(\"ERROR\")\n",
    "import time\n",
    "import diversipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d799a2f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "Run = namedtuple(\"Run\",[\"config\", \"run_logger\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "40954052",
   "metadata": {},
   "outputs": [],
   "source": [
    "run = Run(config={'threads':8, 'analysis':{'parameters':\n",
    "                                           {'tree_topology_change_penalty': 0.0, \n",
    "                                            'prediction_change_cost': 0.0,\n",
    "                                            'data_summarization_fraction': 1.0}}}, \n",
    "          run_logger=logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "711d4886",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'facebook'\n",
    "original_dataset = read_dataset(dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "337a8ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_fraction = 0.2\n",
    "training_fraction = 0.1\n",
    "update_fraction = 0.1\n",
    "\n",
    "train_dataset, test_dataset = train_test_split(original_dataset, test_size=test_fraction)\n",
    "train_dataset = train_dataset.copy()\n",
    "test_dataset = test_dataset.copy()\n",
    "\n",
    "baseline_dataset = train_dataset.sample(frac=training_fraction)\n",
    "update_num_samples = int(train_dataset.shape[0]*update_fraction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d5635e61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48192, 48192)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_dataset.shape[0], update_num_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "10f45111",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "207.33140349388123"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job1 = train(dataset_name, baseline_dataset, run=run, verbose=False)\n",
    "job1.wait_to_complete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7a81b8c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_name = \"{}_basejob\".format(dataset_name)\n",
    "job_path = jobs_dir / job_name\n",
    "job1.store(job_path)\n",
    "# upload_job(job_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7089efe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# job1 = Job.from_file(job_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "930cc10d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_test_error(job):\n",
    "    dataset = test_dataset\n",
    "    job_eval = evaluate(dataset_name=dataset_name, dataset=dataset, original_job=job, run=run, verbose=False)\n",
    "    job_eval.wait_to_complete()\n",
    "    predictions = job_eval.get_predictions()\n",
    "\n",
    "    mse= mean_squared_error(dataset[job_eval.dependent_variable], predictions)\n",
    "    return mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f133e529",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_residuals(job):\n",
    "    dataset = train_dataset\n",
    "    job_eval = evaluate(dataset_name=dataset_name, dataset=dataset, original_job=job, run=run, verbose=False)\n",
    "    job_eval.wait_to_complete()\n",
    "    predictions = job_eval.get_predictions()\n",
    "    residuals = np.absolute(dataset[job_eval.dependent_variable] - predictions)\n",
    "    return residuals"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0c829c6c",
   "metadata": {},
   "source": [
    "job_eval = evaluate(dataset_name=dataset_name, dataset=D, original_job=job1, run=run, verbose=False)\n",
    "\n",
    "job_eval.wait_to_complete()\n",
    "\n",
    "predictions = job_eval.get_predictions()\n",
    "\n",
    "residuals = np.absolute(D[job_eval.dependent_variable] - predictions)\n",
    "\n",
    "mse= mean_squared_error(D[job_eval.dependent_variable], predictions)\n",
    "print(\"mse: {:e}\".format(mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b37f2621",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mse: 4.477813e+02\n"
     ]
    }
   ],
   "source": [
    "print(\"mse: {:e}\".format(compute_test_error(job1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9bea824b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: 3.811826e+02\n",
      "2: 3.587182e+02\n",
      "3: 3.723074e+02\n"
     ]
    }
   ],
   "source": [
    "job_prev = job1\n",
    "for step in range(1,4):\n",
    "    \n",
    "    train_dataset['indicator'] = get_residuals(job_prev)\n",
    "#     D_update = train_dataset.sample(n=2000)\n",
    "#     D_update.drop(columns=['indicator'], inplace=True)\n",
    "    largest = train_dataset.nlargest(n=update_num_samples, columns=['indicator'])\n",
    "    largest.drop(columns=['indicator'], inplace=True)\n",
    "    train_dataset.drop(columns=['indicator'], inplace=True)\n",
    "    D_update=largest\n",
    "#     dupdate = diversipy.subset.psa_select(largest.to_numpy(), update_num_samples)\n",
    "#     D_update = pd.DataFrame(\n",
    "#             data=dupdate, columns=largest.columns)\n",
    "\n",
    "\n",
    "\n",
    "    job_update = update(dataset_name=dataset_name, dataset=D_update, original_job=job_prev, \n",
    "                        run=run, verbose=False, force=True)\n",
    "    job_update.wait_to_complete()\n",
    "    \n",
    "    print(\"{}: {:e}\".format(step, compute_test_error(job_update)))\n",
    "    job_prev = job_update"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8d73e2d3",
   "metadata": {},
   "source": [
    "1: 9.652314e+08\n",
    "2: 9.490314e+08\n",
    "3: 9.489200e+08\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "66b56e85",
   "metadata": {},
   "source": [
    "1: 7.125051e+08\n",
    "2: 6.140740e+08\n",
    "3: 5.980599e+08\n",
    "4: 5.464471e+08\n",
    "5: 5.371015e+08\n",
    "6: 4.974671e+08"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a0e9adc8",
   "metadata": {},
   "source": [
    "1: 8.311670e+08\n",
    "2: 8.334730e+08\n",
    "3: 8.218152e+08\n",
    "4: 8.154660e+08\n",
    "5: 8.047903e+08\n",
    "6: 7.250629e+08\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c64fc7f1",
   "metadata": {},
   "source": [
    "1: 8.102307e+08\n",
    "2: 8.042935e+08\n",
    "3: 7.825746e+08\n",
    "4: 7.676244e+08\n",
    "5: 7.459378e+08\n",
    "6: 6.338819e+08"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
